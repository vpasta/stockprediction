--- Memulai pelatihan model GRU untuk TSLA (Epochs: 200, LR: 0.1, Dropout: 0.2, Patience: 20, Batch Size: 16, Lookback Window: 90) ---
Epoch 1/200, Train Loss: 0.022355, Val Loss: 0.030934
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 2/200, Train Loss: 0.010208, Val Loss: 0.019741
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 3/200, Train Loss: 0.005891, Val Loss: 0.010430
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 4/200, Train Loss: 0.003336, Val Loss: 0.004544
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 5/200, Train Loss: 0.002458, Val Loss: 0.003523
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 6/200, Train Loss: 0.002140, Val Loss: 0.002526
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 7/200, Train Loss: 0.001768, Val Loss: 0.002612
Validation loss tidak meningkat. Patience: 1/20
Epoch 8/200, Train Loss: 0.001914, Val Loss: 0.002169
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 9/200, Train Loss: 0.001824, Val Loss: 0.002161
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 10/200, Train Loss: 0.001602, Val Loss: 0.002270
Validation loss tidak meningkat. Patience: 1/20
Epoch 11/200, Train Loss: 0.001612, Val Loss: 0.003319
Validation loss tidak meningkat. Patience: 2/20
Epoch 12/200, Train Loss: 0.001461, Val Loss: 0.002133
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 13/200, Train Loss: 0.001350, Val Loss: 0.001923
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 14/200, Train Loss: 0.001221, Val Loss: 0.001895
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 15/200, Train Loss: 0.001279, Val Loss: 0.001815
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 16/200, Train Loss: 0.001311, Val Loss: 0.001807
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 17/200, Train Loss: 0.001204, Val Loss: 0.001860
Validation loss tidak meningkat. Patience: 1/20
Epoch 18/200, Train Loss: 0.001181, Val Loss: 0.002130
Validation loss tidak meningkat. Patience: 2/20
Epoch 19/200, Train Loss: 0.001179, Val Loss: 0.001794
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 20/200, Train Loss: 0.001177, Val Loss: 0.002495
Validation loss tidak meningkat. Patience: 1/20
Epoch 21/200, Train Loss: 0.001123, Val Loss: 0.002244
Validation loss tidak meningkat. Patience: 2/20
Epoch 22/200, Train Loss: 0.001083, Val Loss: 0.001796
Validation loss tidak meningkat. Patience: 3/20
Epoch 23/200, Train Loss: 0.001077, Val Loss: 0.001832
Validation loss tidak meningkat. Patience: 4/20
Epoch 24/200, Train Loss: 0.000976, Val Loss: 0.002144
Validation loss tidak meningkat. Patience: 5/20
Epoch 25/200, Train Loss: 0.001064, Val Loss: 0.001749
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 26/200, Train Loss: 0.001055, Val Loss: 0.001758
Validation loss tidak meningkat. Patience: 1/20
Epoch 27/200, Train Loss: 0.001079, Val Loss: 0.001741
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 28/200, Train Loss: 0.000966, Val Loss: 0.001723
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 29/200, Train Loss: 0.000962, Val Loss: 0.001831
Validation loss tidak meningkat. Patience: 1/20
Epoch 30/200, Train Loss: 0.001055, Val Loss: 0.001826
Validation loss tidak meningkat. Patience: 2/20
Epoch 31/200, Train Loss: 0.001027, Val Loss: 0.002591
Validation loss tidak meningkat. Patience: 3/20
Epoch 32/200, Train Loss: 0.000996, Val Loss: 0.001757
Validation loss tidak meningkat. Patience: 4/20
Epoch 33/200, Train Loss: 0.000934, Val Loss: 0.001719
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 34/200, Train Loss: 0.000881, Val Loss: 0.002035
Validation loss tidak meningkat. Patience: 1/20
Epoch 35/200, Train Loss: 0.000962, Val Loss: 0.001799
Validation loss tidak meningkat. Patience: 2/20
Epoch 36/200, Train Loss: 0.000954, Val Loss: 0.001910
Validation loss tidak meningkat. Patience: 3/20
Epoch 37/200, Train Loss: 0.000966, Val Loss: 0.001737
Validation loss tidak meningkat. Patience: 4/20
Epoch 38/200, Train Loss: 0.000889, Val Loss: 0.001692
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 39/200, Train Loss: 0.000992, Val Loss: 0.001722
Validation loss tidak meningkat. Patience: 1/20
Epoch 40/200, Train Loss: 0.000947, Val Loss: 0.001963
Validation loss tidak meningkat. Patience: 2/20
Epoch 41/200, Train Loss: 0.000912, Val Loss: 0.001696
Validation loss tidak meningkat. Patience: 3/20
Epoch 42/200, Train Loss: 0.000954, Val Loss: 0.001782
Validation loss tidak meningkat. Patience: 4/20
Epoch 43/200, Train Loss: 0.000866, Val Loss: 0.001912
Validation loss tidak meningkat. Patience: 5/20
Epoch 44/200, Train Loss: 0.000864, Val Loss: 0.001752
Validation loss tidak meningkat. Patience: 6/20
Epoch 45/200, Train Loss: 0.000894, Val Loss: 0.001705
Validation loss tidak meningkat. Patience: 7/20
Epoch 46/200, Train Loss: 0.000862, Val Loss: 0.002500
Validation loss tidak meningkat. Patience: 8/20
Epoch 47/200, Train Loss: 0.000866, Val Loss: 0.001925
Validation loss tidak meningkat. Patience: 9/20
Epoch 48/200, Train Loss: 0.000895, Val Loss: 0.001705
Validation loss tidak meningkat. Patience: 10/20
Epoch 49/200, Train Loss: 0.000883, Val Loss: 0.001671
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 50/200, Train Loss: 0.000896, Val Loss: 0.001747
Validation loss tidak meningkat. Patience: 1/20
Epoch 51/200, Train Loss: 0.000841, Val Loss: 0.001906
Validation loss tidak meningkat. Patience: 2/20
Epoch 52/200, Train Loss: 0.000881, Val Loss: 0.001678
Validation loss tidak meningkat. Patience: 3/20
Epoch 53/200, Train Loss: 0.000761, Val Loss: 0.001657
Validation loss meningkat. Menyimpan bobot model terbaik.
Epoch 54/200, Train Loss: 0.000880, Val Loss: 0.001924
Validation loss tidak meningkat. Patience: 1/20
Epoch 55/200, Train Loss: 0.000784, Val Loss: 0.001771
Validation loss tidak meningkat. Patience: 2/20
Epoch 56/200, Train Loss: 0.000766, Val Loss: 0.001723
Validation loss tidak meningkat. Patience: 3/20
Epoch 57/200, Train Loss: 0.000848, Val Loss: 0.001779
Validation loss tidak meningkat. Patience: 4/20
Epoch 58/200, Train Loss: 0.000842, Val Loss: 0.001757
Validation loss tidak meningkat. Patience: 5/20
Epoch 59/200, Train Loss: 0.000798, Val Loss: 0.001676
Validation loss tidak meningkat. Patience: 6/20
Epoch 60/200, Train Loss: 0.000798, Val Loss: 0.002390
Validation loss tidak meningkat. Patience: 7/20
Epoch 61/200, Train Loss: 0.000846, Val Loss: 0.001823
Validation loss tidak meningkat. Patience: 8/20
Epoch 62/200, Train Loss: 0.000772, Val Loss: 0.001685
Validation loss tidak meningkat. Patience: 9/20
Epoch 63/200, Train Loss: 0.000786, Val Loss: 0.001692
Validation loss tidak meningkat. Patience: 10/20
Epoch 64/200, Train Loss: 0.000781, Val Loss: 0.001679
Validation loss tidak meningkat. Patience: 11/20
Epoch 65/200, Train Loss: 0.000832, Val Loss: 0.001668
Validation loss tidak meningkat. Patience: 12/20
Epoch 66/200, Train Loss: 0.000792, Val Loss: 0.001735
Validation loss tidak meningkat. Patience: 13/20
Epoch 67/200, Train Loss: 0.000765, Val Loss: 0.001756
Validation loss tidak meningkat. Patience: 14/20
Epoch 68/200, Train Loss: 0.000730, Val Loss: 0.002330
Validation loss tidak meningkat. Patience: 15/20
Epoch 69/200, Train Loss: 0.000732, Val Loss: 0.002058
Validation loss tidak meningkat. Patience: 16/20
Epoch 70/200, Train Loss: 0.000740, Val Loss: 0.001932
Validation loss tidak meningkat. Patience: 17/20
Epoch 71/200, Train Loss: 0.000763, Val Loss: 0.001792
Validation loss tidak meningkat. Patience: 18/20
Epoch 72/200, Train Loss: 0.000812, Val Loss: 0.001667
Validation loss tidak meningkat. Patience: 19/20
Epoch 73/200, Train Loss: 0.000765, Val Loss: 0.001699
Validation loss tidak meningkat. Patience: 20/20
Early stopping dipicu setelah 73 epoch tanpa peningkatan validasi loss.
--- Early stopping dipicu ---
--- Pelatihan selesai dengan sukses ---
Bobot model TERBAIK berhasil disimpan ke: GRU_weights_TSLA_H128_L90_F15_LR01_DO02.npz
Pelatihan selesai dalam 198.20 detik. Final Train Loss: 0.000765, Final Val Loss (best): 0.001657
